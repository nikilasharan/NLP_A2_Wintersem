{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "str1=\"The town where I was born is on the east coast\"\n",
    "str2=\"the little yellow dog barked at the cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NounGrammar = ('''\n",
    "    NP: {<DT>?<JJ>*<NN>} # NP\n",
    "    ''')\n",
    "VerbGrammar = ('''\n",
    "    Ph: {<VB*>+<DT>?<NN*>+} # VB\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "str1\n",
      "[('The', 'DT'), ('town', 'NN'), ('where', 'WRB'), ('I', 'PRP'), ('was', 'VBD'), ('born', 'VBN'), ('is', 'VBZ'), ('on', 'IN'), ('the', 'DT'), ('east', 'NN'), ('coast', 'NN')]\n",
      "str2\n",
      "[('the', 'DT'), ('little', 'JJ'), ('yellow', 'JJ'), ('dog', 'NN'), ('barked', 'VBD'), ('at', 'IN'), ('the', 'DT'), ('cat', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "chunkParser = nltk.RegexpParser(NounGrammar)\n",
    "chunkParser2 = nltk.RegexpParser(VerbGrammar)\n",
    "tagged2 = nltk.pos_tag(nltk.word_tokenize(str2))\n",
    "tagged1 = nltk.pos_tag(nltk.word_tokenize(str1))\n",
    "print(\"str1\")\n",
    "print(tagged1)\n",
    "print(\"str2\")\n",
    "print(tagged2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOUN PHRASE CHUNKING\n",
      "(S\n",
      "  (NP The/DT town/NN)\n",
      "  where/WRB\n",
      "  I/PRP\n",
      "  was/VBD\n",
      "  born/VBN\n",
      "  is/VBZ\n",
      "  on/IN\n",
      "  (NP the/DT east/NN)\n",
      "  (NP coast/NN))\n",
      "(NP The/DT town/NN)\n",
      "(NP the/DT east/NN)\n",
      "(NP coast/NN)\n",
      "(S\n",
      "  (NP the/DT little/JJ yellow/JJ dog/NN)\n",
      "  barked/VBD\n",
      "  at/IN\n",
      "  (NP the/DT cat/NN))\n",
      "(NP the/DT little/JJ yellow/JJ dog/NN)\n",
      "(NP the/DT cat/NN)\n",
      "------------------------\n",
      "VERB PHRASE CHUNKING\n",
      "(S\n",
      "  (NP The/DT town/NN)\n",
      "  where/WRB\n",
      "  I/PRP\n",
      "  was/VBD\n",
      "  born/VBN\n",
      "  is/VBZ\n",
      "  on/IN\n",
      "  (NP the/DT east/NN)\n",
      "  (NP coast/NN))\n",
      "(NP The/DT town/NN)\n",
      "(NP the/DT east/NN)\n",
      "(NP coast/NN)\n",
      "(S\n",
      "  (NP the/DT little/JJ yellow/JJ dog/NN)\n",
      "  barked/VBD\n",
      "  at/IN\n",
      "  (NP the/DT cat/NN))\n",
      "(NP the/DT little/JJ yellow/JJ dog/NN)\n",
      "(NP the/DT cat/NN)\n"
     ]
    }
   ],
   "source": [
    "print(\"NOUN PHRASE CHUNKING\")\n",
    "tree1 = chunkParser.parse(tagged1)\n",
    "for subtree in tree1.subtrees():\n",
    "    print(subtree)\n",
    "\n",
    "tree2 = chunkParser.parse(tagged2)\n",
    "for subtree in tree2.subtrees():\n",
    "    print(subtree)\n",
    "    \n",
    "print(\"------------------------\")\n",
    "print(\"VERB PHRASE CHUNKING\")\n",
    "Verbtree1 = chunkParser2.parse(tagged1)\n",
    "for subtree in tree1.subtrees():\n",
    "    print(subtree)\n",
    "\n",
    "Verbtree2 = chunkParser2.parse(tagged2)\n",
    "for subtree in tree2.subtrees():\n",
    "    print(subtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree1.draw()\n",
    "tree2.draw()\n",
    "Verbtree1.draw()\n",
    "Verbtree2.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"All 112 people admitted to an ITBP quarantine facility for over a fortnight have tested negative for coronavirus and\"+ \"are expected to be released on Friday.\"\n",
    "\n",
    "doc = nlp(example)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
